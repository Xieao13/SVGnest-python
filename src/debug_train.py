import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import os
import json
import logging
import sys
from tqdm import tqdm

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

# ä½¿ç”¨åŸæœ‰çš„æ•°æ®é›†å’Œcollate_fn
from train_savedata import BinPackingDataset, collate_fn


def debug_data_loading():
    """è°ƒè¯•æ•°æ®åŠ è½½è¿‡ç¨‹"""
    print("=" * 60)
    print("ğŸ” å¼€å§‹è°ƒè¯•æ•°æ®åŠ è½½è¿‡ç¨‹...")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    data_file = '../output/placement-0412.jsonl'
    dataset = BinPackingDataset(data_file)
    
    print(f"âœ… æ•°æ®é›†å¤§å°: {len(dataset)}")
    
    # æ£€æŸ¥å‰å‡ ä¸ªæ ·æœ¬
    print("\nğŸ“Š æ£€æŸ¥å‰3ä¸ªæ ·æœ¬çš„æ•°æ®:")
    for i in range(min(3, len(dataset))):
        sample = dataset[i]
        print(f"\næ ·æœ¬ {i}:")
        print(f"  bin shape: {sample['bin'].shape}, values: {sample['bin'].tolist()}")
        print(f"  parts shape: {sample['parts'].shape}")
        print(f"  placement_order shape: {sample['placement_order'].shape}")
        print(f"  placement_order values: {sample['placement_order'].tolist()}")
        print(f"  rotation shape: {sample['rotation'].shape}")
        print(f"  rotation values: {sample['rotation'].tolist()}")
        print(f"  valid_length: {sample['valid_length']}")
        print(f"  efficiency: {sample['efficiency']:.4f}")
        
        # æ£€æŸ¥placement_orderæ˜¯å¦åˆç†
        parts_count = len(sample['parts'])
        placement_order = sample['placement_order'].tolist()
        print(f"  é›¶ä»¶æ•°é‡: {parts_count}")
        print(f"  placement_orderèŒƒå›´: [{min(placement_order)}, {max(placement_order)}]")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºè¿ç»­ç´¢å¼•
        expected_range = set(range(parts_count))
        actual_range = set(placement_order)
        if expected_range != actual_range:
            print(f"  âš ï¸ è­¦å‘Š: placement_orderä¸æ˜¯è¿ç»­ç´¢å¼•!")
            print(f"     æœŸæœ›: {sorted(expected_range)}")
            print(f"     å®é™…: {sorted(actual_range)}")
        else:
            print(f"  âœ… placement_orderæ˜¯è¿ç»­ç´¢å¼•")
    
    # æ£€æŸ¥æ•°æ®åŠ è½½å™¨
    print(f"\nğŸ”„ æ£€æŸ¥DataLoader...")
    train_loader = DataLoader(
        dataset, batch_size=4, shuffle=False, collate_fn=collate_fn, drop_last=True
    )
    
    # è·å–ä¸€ä¸ªbatch
    batch = next(iter(train_loader))
    print(f"\nğŸ“¦ Batchæ•°æ®å½¢çŠ¶:")
    for key, value in batch.items():
        if isinstance(value, torch.Tensor):
            print(f"  {key}: {value.shape}, dtype: {value.dtype}")
            if key == 'placement_orders':
                print(f"    èŒƒå›´: [{value.min().item()}, {value.max().item()}]")
                print(f"    å‰ä¸¤ä¸ªæ ·æœ¬: {value[:2].tolist()}")
            elif key == 'rotations':
                print(f"    èŒƒå›´: [{value.min().item()}, {value.max().item()}]")
                print(f"    å‰ä¸¤ä¸ªæ ·æœ¬: {value[:2].tolist()}")
            elif key == 'valid_lengths':
                print(f"    å€¼: {value.tolist()}")
        else:
            print(f"  {key}: {type(value)}")
    
    # æ£€æŸ¥æœ€å¤§åºåˆ—é•¿åº¦
    max_seq_len = max(len(item['parts']) for i in range(min(1000, len(dataset))) for item in [dataset[i]])
    print(f"\nğŸ“ å‰1000ä¸ªæ ·æœ¬çš„æœ€å¤§åºåˆ—é•¿åº¦: {max_seq_len}")
    
    return dataset, train_loader, max_seq_len


def debug_model_forward():
    """è°ƒè¯•æ¨¡å‹å‰å‘ä¼ æ’­"""
    print("\n" + "=" * 60)
    print("ğŸ” å¼€å§‹è°ƒè¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    dataset, train_loader, max_seq_len = debug_data_loading()
    
    # åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„æ¨¡å‹ç”¨äºæµ‹è¯•
    class SimpleTestNetwork(nn.Module):
        def __init__(self, input_dim, hidden_dim, seq_len, bin_dim=2):
            super(SimpleTestNetwork, self).__init__()
            self.seq_len = seq_len
            self.hidden_dim = hidden_dim
            
            # ç®€åŒ–çš„ç¼–ç å™¨
            self.bin_encoder = nn.Linear(bin_dim, 32)
            self.part_encoder = nn.Linear(input_dim, 64)
            
            # ç®€åŒ–çš„è¾“å‡ºå±‚
            self.dense = nn.Linear(96, seq_len)  # 64 + 32
            self.rotation_output = nn.Linear(96, 4)
            
        def forward(self, inputs, bin_info, target_indices=None):
            batch_size, seq_len_actual = inputs.shape[:2]
            
            print(f"  è¾“å…¥å½¢çŠ¶ - inputs: {inputs.shape}, bin_info: {bin_info.shape}")
            
            # ç¼–ç 
            bin_encoded = self.bin_encoder(bin_info)  # [batch_size, 32]
            bin_encoded = bin_encoded.unsqueeze(1).expand(-1, seq_len_actual, -1)  # [batch_size, seq_len, 32]
            
            parts_encoded = self.part_encoder(inputs)  # [batch_size, seq_len, 64]
            
            print(f"  ç¼–ç åå½¢çŠ¶ - parts_encoded: {parts_encoded.shape}, bin_encoded: {bin_encoded.shape}")
            
            # æ‹¼æ¥
            combined = torch.cat([parts_encoded, bin_encoded], dim=-1)  # [batch_size, seq_len, 96]
            
            print(f"  æ‹¼æ¥åå½¢çŠ¶: {combined.shape}")
            
            # ç®€å•çš„å¹³å‡æ± åŒ–
            pooled = combined.mean(dim=1)  # [batch_size, 96]
            
            # è¾“å‡º
            placement_logits = self.dense(pooled)  # [batch_size, seq_len]
            rotation_logits = self.rotation_output(pooled)  # [batch_size, 4]
            
            print(f"  è¾“å‡ºå½¢çŠ¶ - placement_logits: {placement_logits.shape}, rotation_logits: {rotation_logits.shape}")
            
            # æ£€æŸ¥logitsçš„æ•°å€¼èŒƒå›´
            print(f"  placement_logitsèŒƒå›´: [{placement_logits.min().item():.3f}, {placement_logits.max().item():.3f}]")
            print(f"  rotation_logitsèŒƒå›´: [{rotation_logits.min().item():.3f}, {rotation_logits.max().item():.3f}]")
            
            # æ¨¡æ‹Ÿåºåˆ—è¾“å‡º (ä¸ºäº†å…¼å®¹åŸæ¥çš„è®­ç»ƒä»£ç )
            placement_logits_seq = placement_logits.unsqueeze(1).expand(-1, seq_len_actual, -1)
            rotation_logits_seq = rotation_logits.unsqueeze(1).expand(-1, seq_len_actual, -1)
            
            return placement_logits_seq, rotation_logits_seq
    
    # è®¾å¤‡
    device = torch.device("cpu")  # å…ˆç”¨CPUè°ƒè¯•
    
    # åˆ›å»ºæ¨¡å‹
    model = SimpleTestNetwork(input_dim=2, hidden_dim=128, seq_len=max_seq_len)
    model.to(device)
    
    print(f"\nğŸ¤– åˆ›å»ºç®€åŒ–æµ‹è¯•æ¨¡å‹, seq_len={max_seq_len}")
    
    # æµ‹è¯•ä¸€ä¸ªbatch
    batch = next(iter(train_loader))
    parts = batch['parts'].to(device)
    bins = batch['bins'].to(device)
    placement_targets = batch['placement_orders'].to(device)
    rotation_targets = batch['rotations'].to(device)
    valid_lengths = batch['valid_lengths'].to(device)
    
    print(f"\nğŸ”„ æµ‹è¯•å‰å‘ä¼ æ’­...")
    try:
        with torch.no_grad():
            placement_logits, rotation_logits = model(parts, bins, placement_targets)
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ!")
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # æµ‹è¯•æŸå¤±è®¡ç®—
    print(f"\nğŸ“Š æµ‹è¯•æŸå¤±è®¡ç®—...")
    try:
        total_placement_loss = 0
        total_rotation_loss = 0
        valid_count = 0
        
        for i in range(parts.size(0)):
            valid_len = valid_lengths[i].item()
            print(f"  æ ·æœ¬ {i}: valid_len={valid_len}")
            
            for j in range(min(valid_len, placement_logits.size(1))):
                # æ£€æŸ¥ç›®æ ‡å€¼æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
                p_target = placement_targets[i, j].item()
                r_target = rotation_targets[i, j].item()
                
                print(f"    ä½ç½® {j}: p_target={p_target}, r_target={r_target}")
                
                if p_target >= placement_logits.size(-1):
                    print(f"    âš ï¸ è­¦å‘Š: placement_target {p_target} è¶…å‡ºlogitsèŒƒå›´ {placement_logits.size(-1)}")
                    continue
                
                if r_target >= 4:
                    print(f"    âš ï¸ è­¦å‘Š: rotation_target {r_target} è¶…å‡ºèŒƒå›´ [0,3]")
                    continue
                
                # è®¡ç®—æŸå¤±
                p_loss = F.cross_entropy(
                    placement_logits[i, j].unsqueeze(0),
                    placement_targets[i, j].unsqueeze(0)
                )
                
                r_loss = F.cross_entropy(
                    rotation_logits[i, j].unsqueeze(0),
                    rotation_targets[i, j].unsqueeze(0)
                )
                
                total_placement_loss += p_loss.item()
                total_rotation_loss += r_loss.item()
                valid_count += 1
                
                if j < 3:  # åªæ‰“å°å‰3ä¸ªä½ç½®çš„è¯¦ç»†ä¿¡æ¯
                    print(f"    ä½ç½® {j}: p_loss={p_loss.item():.4f}, r_loss={r_loss.item():.4f}")
        
        if valid_count > 0:
            avg_p_loss = total_placement_loss / valid_count
            avg_r_loss = total_rotation_loss / valid_count
            total_loss = avg_p_loss + avg_r_loss
            
            print(f"\nğŸ“ˆ æŸå¤±ç»Ÿè®¡:")
            print(f"  å¹³å‡placement_loss: {avg_p_loss:.4f}")
            print(f"  å¹³å‡rotation_loss: {avg_r_loss:.4f}")
            print(f"  æ€»æŸå¤±: {total_loss:.4f}")
            print(f"  æœ‰æ•ˆæ ·æœ¬æ•°: {valid_count}")
            
            if total_loss > 100:
                print(f"âš ï¸ è­¦å‘Š: æŸå¤±å€¼è¿‡å¤§!")
            else:
                print(f"âœ… æŸå¤±å€¼åœ¨åˆç†èŒƒå›´å†…")
        
    except Exception as e:
        print(f"âŒ æŸå¤±è®¡ç®—å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def debug_data_statistics():
    """åˆ†ææ•°æ®é›†çš„ç»Ÿè®¡ç‰¹æ€§"""
    print("\n" + "=" * 60)
    print("ğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡åˆ†æ...")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    data_file = '../output/placement-0412.jsonl'
    dataset = BinPackingDataset(data_file)
    
    # ç»Ÿè®¡ä¿¡æ¯
    seq_lengths = []
    placement_ranges = []
    rotation_ranges = []
    efficiencies = []
    bin_sizes = []
    
    print("ğŸ”„ åˆ†æå‰1000ä¸ªæ ·æœ¬...")
    for i in range(min(1000, len(dataset))):
        sample = dataset[i]
        
        seq_len = sample['valid_length']
        seq_lengths.append(seq_len)
        
        placement_order = sample['placement_order'].tolist()
        placement_ranges.append([min(placement_order), max(placement_order)])
        
        rotation = sample['rotation'].tolist()
        rotation_ranges.append([min(rotation), max(rotation)])
        
        efficiencies.append(sample['efficiency'])
        
        bin_size = sample['bin'].tolist()
        bin_sizes.append(bin_size)
    
    print(f"\nğŸ“Š ç»Ÿè®¡ç»“æœ:")
    print(f"  åºåˆ—é•¿åº¦: æœ€å°={min(seq_lengths)}, æœ€å¤§={max(seq_lengths)}, å¹³å‡={np.mean(seq_lengths):.2f}")
    
    print(f"  placement_orderèŒƒå›´:")
    min_vals = [r[0] for r in placement_ranges]
    max_vals = [r[1] for r in placement_ranges]
    print(f"    æœ€å°å€¼èŒƒå›´: [{min(min_vals)}, {max(min_vals)}]")
    print(f"    æœ€å¤§å€¼èŒƒå›´: [{min(max_vals)}, {max(max_vals)}]")
    
    print(f"  rotationèŒƒå›´:")
    min_rots = [r[0] for r in rotation_ranges]
    max_rots = [r[1] for r in rotation_ranges]
    print(f"    æœ€å°å€¼èŒƒå›´: [{min(min_rots)}, {max(min_rots)}]")
    print(f"    æœ€å¤§å€¼èŒƒå›´: [{min(max_rots)}, {max(max_rots)}]")
    
    print(f"  æ•ˆç‡: æœ€å°={min(efficiencies):.4f}, æœ€å¤§={max(efficiencies):.4f}, å¹³å‡={np.mean(efficiencies):.4f}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸çš„placement_order
    problematic_samples = []
    for i in range(min(100, len(dataset))):
        sample = dataset[i]
        seq_len = sample['valid_length']
        placement_order = sample['placement_order'].tolist()
        
        expected = set(range(seq_len))
        actual = set(placement_order)
        
        if expected != actual:
            problematic_samples.append(i)
    
    if problematic_samples:
        print(f"\nâš ï¸ å‘ç° {len(problematic_samples)} ä¸ªé—®é¢˜æ ·æœ¬:")
        for i in problematic_samples[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            sample = dataset[i]
            seq_len = sample['valid_length']
            placement_order = sample['placement_order'].tolist()
            print(f"  æ ·æœ¬ {i}: seq_len={seq_len}, placement_order={placement_order}")
    else:
        print(f"\nâœ… å‰100ä¸ªæ ·æœ¬çš„placement_orderéƒ½æ­£å¸¸")


def main():
    print("ğŸš€ å¼€å§‹è°ƒè¯•æ¨¡å¼...")
    
    # 1. æ•°æ®ç»Ÿè®¡åˆ†æ
    debug_data_statistics()
    
    # 2. æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•
    debug_model_forward()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ è°ƒè¯•å®Œæˆ! è¯·æ£€æŸ¥ä¸Šè¿°è¾“å‡ºï¼Œç¡®è®¤æ•°æ®å’Œæ¨¡å‹æ˜¯å¦æ­£å¸¸")
    print("=" * 60)


if __name__ == '__main__':
    main() 