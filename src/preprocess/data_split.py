import json
import os
import random
from sklearn.model_selection import train_test_split

def validate_data_item(item, line_num):
    """éªŒè¯å•ä¸ªæ•°æ®é¡¹çš„æœ‰æ•ˆæ€§"""
    try:
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        required_fields = ['bin', 'parts', 'placement_order', 'efficiency']
        for field in required_fields:
            if field not in item:
                print(f"ç¬¬{line_num}è¡Œç¼ºå°‘å­—æ®µ: {field}")
                return False
        
        # æ£€æŸ¥é•¿åº¦ä¸€è‡´æ€§
        parts_len = len(item['parts'])
        placement_order_len = len(item['placement_order'])
        
        # å¦‚æœæœ‰rotationå­—æ®µï¼Œä¹Ÿæ£€æŸ¥å…¶é•¿åº¦
        if 'rotation' in item:
            rotation_len = len(item['rotation'])
            if parts_len != placement_order_len or parts_len != rotation_len:
                print(f"ç¬¬{line_num}è¡Œé•¿åº¦ä¸ä¸€è‡´: parts({parts_len}) vs placement_order({placement_order_len}) vs rotation({rotation_len})")
                return False
        else:
            if parts_len != placement_order_len:
                print(f"ç¬¬{line_num}è¡Œé•¿åº¦ä¸ä¸€è‡´: parts({parts_len}) vs placement_order({placement_order_len})")
                return False
        
        # æ£€æŸ¥placement_orderæ˜¯å¦æ˜¯æœ‰æ•ˆæ’åˆ—
        expected_indices = set(range(parts_len))
        actual_indices = set(item['placement_order'])
        
        if expected_indices != actual_indices:
            missing = expected_indices - actual_indices
            extra = actual_indices - expected_indices
            print(f"ç¬¬{line_num}è¡Œplacement_orderä¸æ˜¯æœ‰æ•ˆæ’åˆ—")
            if missing:
                print(f"  ç¼ºå¤±ç´¢å¼•: {sorted(missing)}")
            if extra:
                print(f"  å¤šä½™ç´¢å¼•: {sorted(extra)}")
            return False
        
        # æ£€æŸ¥ç´¢å¼•èŒƒå›´
        max_index = max(item['placement_order'])
        min_index = min(item['placement_order'])
        if max_index >= parts_len or min_index < 0:
            print(f"ç¬¬{line_num}è¡Œplacement_orderç´¢å¼•è¶…å‡ºèŒƒå›´: [{min_index}, {max_index}], åº”è¯¥åœ¨[0, {parts_len-1}]")
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤
        if len(set(item['placement_order'])) != len(item['placement_order']):
            print(f"ç¬¬{line_num}è¡Œplacement_orderæœ‰é‡å¤å€¼")
            return False
        
        # æ£€æŸ¥partsæ˜¯å¦ä¸ºç©ºæˆ–åŒ…å«æ— æ•ˆå€¼
        if not item['parts'] or any(not isinstance(part, list) or len(part) != 2 for part in item['parts']):
            print(f"ç¬¬{line_num}è¡Œpartsæ ¼å¼æ— æ•ˆ")
            return False
        
        # æ£€æŸ¥binæ ¼å¼
        if not isinstance(item['bin'], list) or len(item['bin']) != 2:
            print(f"ç¬¬{line_num}è¡Œbinæ ¼å¼æ— æ•ˆ")
            return False
        
        return True
        
    except Exception as e:
        print(f"ç¬¬{line_num}è¡Œæ•°æ®éªŒè¯å¤±è´¥: {e}")
        return False

def load_and_filter_data(input_file):
    """åŠ è½½å¹¶è¿‡æ»¤æ•°æ®"""
    data = []
    total_loaded = 0
    valid_count = 0
    
    print(f"ğŸ“‚ æ­£åœ¨åŠ è½½å’ŒéªŒè¯æ•°æ®æ–‡ä»¶: {input_file}")
    
    with open(input_file, 'r') as f:
        for line_num, line in enumerate(f, 1):
            if line.strip():
                try:
                    item = json.loads(line)
                    total_loaded += 1
                    
                    # éªŒè¯æ•°æ®å®Œæ•´æ€§
                    if validate_data_item(item, line_num):
                        data.append(item)
                        valid_count += 1
                    
                except json.JSONDecodeError as e:
                    print(f"ç¬¬{line_num}è¡ŒJSONè§£æå¤±è´¥: {e}")
                    continue
    
    print(f"ğŸ“Š æ•°æ®åŠ è½½ç»Ÿè®¡:")
    print(f"  æ€»å…±è¯»å–: {total_loaded} æ¡æ•°æ®")
    print(f"  æœ‰æ•ˆæ•°æ®: {valid_count} æ¡")
    print(f"  è¿‡æ»¤æ‰: {total_loaded - valid_count} æ¡æ— æ•ˆæ•°æ®")
    print(f"  æœ‰æ•ˆç‡: {valid_count/total_loaded*100:.2f}%" if total_loaded > 0 else "  æœ‰æ•ˆç‡: 0%")
    
    return data

def split_dataset(input_file, train_output_file, test_output_file, split_ratio=0.8):
    """å°†JSONLæ•°æ®é›†æ–‡ä»¶åˆ†å‰²æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ˆå…ˆè¿‡æ»¤æ— æ•ˆæ•°æ®ï¼‰"""
    
    # åŠ è½½å¹¶è¿‡æ»¤æ•°æ®
    data = load_and_filter_data(input_file)

    if not data:
        print(f"âš ï¸ è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯ä»¥åˆ†å‰²")
        return

    print(f"\nğŸ”„ å¼€å§‹åˆ†å‰²æ•°æ®é›†...")
    
    # ä½¿ç”¨train_test_splitè¿›è¡Œåˆ†å‰²ï¼Œç¡®ä¿å›ºå®šç§å­ä»¥ä¾¿ç»“æœå¯å¤ç°
    train_data, test_data = train_test_split(data, train_size=split_ratio, random_state=42)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = os.path.dirname(train_output_file)
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        
    output_dir = os.path.dirname(test_output_file)
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # å°†åˆ†å‰²åçš„æ•°æ®å†™å…¥æ–°çš„JSONLæ–‡ä»¶
    with open(train_output_file, 'w') as f:
        for entry in train_data:
            json.dump(entry, f)
            f.write('\n')

    with open(test_output_file, 'w') as f:
        for entry in test_data:
            json.dump(entry, f)
            f.write('\n')

    print(f"âœ… æ•°æ®é›†åˆ†å‰²å®Œæˆ:")
    print(f"  è®­ç»ƒé›†: {len(train_data)} æ¡æ•°æ® -> {train_output_file}")
    print(f"  æµ‹è¯•é›†: {len(test_data)} æ¡æ•°æ® -> {test_output_file}")
    print(f"  åˆ†å‰²æ¯”ä¾‹: {len(train_data)/(len(train_data)+len(test_data))*100:.1f}% / {len(test_data)/(len(train_data)+len(test_data))*100:.1f}%")

if __name__ == "__main__":
    folder_path = './data/placement-0529-ga-20epoch-norotation'
    input_dataset_path = os.path.join(folder_path, 'raw_data.jsonl')
    train_output_path = os.path.join(folder_path, 'train.jsonl')
    test_output_path = os.path.join(folder_path, 'test.jsonl')

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_dataset_path):
        print(f"âŒ é”™è¯¯: è¾“å…¥æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ {input_dataset_path}")
        print(f"è¯·ç¡®ä¿åŸå§‹æ•°æ®æ–‡ä»¶å­˜åœ¨")
    else:
        print("ğŸš€ å¼€å§‹æ•°æ®éªŒè¯å’Œåˆ†å‰²...")
        split_dataset(input_dataset_path, train_output_path, test_output_path)
